@misc{geng2025accumulating,
  title = {Accumulating Context Changes the Beliefs of Language Models},
  author = {Jiayi Geng and Howard Chen and Ryan Liu and Manoel Horta Ribeiro and Robb Willer and Graham Neubig and Thomas L Griffiths},
  journal = {Preprint},
  year = {2025},
  month = {11},
  url = {https://arxiv.org/abs/2511.01805},
  code = {https://github.com/JiayiGeng/lm-belief-change},
  preview = {accumulating.png},
  selected = {true},
  description = {Investigating how accumulating context shifts the beliefs of language models.}
}

@misc{qiu2025alitag,
  title = {Alita-G: Self-Evolving Generative Agent for Agent Generation},
  author = {Jiahao Qiu and Xuan Qi and Hongru Wang and Xinzhe Juan and Yimin Wang and Zelin Zhao and Jiayi Geng and Jiacheng Guo and Peihang Li and Jingzhe Shi and Shilong Liu and Mengdi Wang},
  journal = {Preprint},
  year = {2025},
  month = {10},
  url = {https://arxiv.org/abs/2510.23601},
  preview = {alitag.png},
  selected = {false},
  description = {A self-evolution framework that transforms a general-purpose agent into a domain expert by generating, abstracting, and curating MCP tools.}
}

@misc{qiu2025physics,
  title = {Physics Supernova: AI Agent Matches Elite Gold Medalists at IPhO 2025},
  author = {Jiahao Qiu and Jingzhe Shi and Xinzhe Juan and Zelin Zhao and Jiayi Geng and Shilong Liu and Hongru Wang and Sanfeng Wu and Mengdi Wang},
  journal = {Preprint},
  year = {2025},
  month = {9},
  url = {https://arxiv.org/abs/2509.01659},
  code = {https://github.com/CharlesQ9/Physics-Supernova},
  preview = {physics.png},
  selected = {false},
  description = {An AI agent that matches elite gold medalists at the International Physics Olympiad 2025.}
}

@article{gao2025survey,
  title = {A Survey of Self-Evolving Agents: On Path to Artificial Super Intelligence},
  author = {Huan-ang Gao* and Jiayi Geng* and Wenyue Hua* and Mengkang Hu* and Xinzhe Juan* and Hongzhang Liu* and Shilong Liu* and Jiahao Qiu* and Xuan Qi* and Qihan Ren* and Yiran Wu* and Hongru Wang* and Han Xiao* and Yuhang Zhou* and Shaokun Zhang* and Jiayi Zhang and Jinyu Xiang and Yixiong Fang and Qiwen Zhao and Dongrui Liu and Cheng Qian and Zhenhailong Wang and Minda Hu and Huazheng Wang and Qingyun Wu and Heng Ji and Mengdi Wang},
  journal = {TMLR 2026},
  year = {2025},
  month = {7},
  url = {https://arxiv.org/abs/2507.21046},
  code = {https://github.com/CharlesQ9/Self-Evolving-Agents},
  preview = {self-evolving.png},
  selected = {true},
  description = {A comprehensive survey of self-evolving agents and their path toward artificial super intelligence.}
}

@inproceedings{liu2025mind,
  title = {Mind Your Step (by Step): Chain-of-Thought Can Reduce Performance on Tasks Where Thinking Makes Humans Worse},
  author = {Ryan Liu* and Jiayi Geng* and Addison J Wu and Ilia Sucholutsky and Tania Lombrozo and Thomas L Griffiths},
  booktitle = {ICML 2025},
  year = {2025},
  month = {6},
  url = {https://arxiv.org/abs/2410.21333},
  code = {https://github.com/JiayiGeng/CoT_overthinking},
  preview = {mind_your_step.png},
  selected = {true},
  description = {Demonstrating that chain-of-thought prompting can reduce LLM performance on tasks where deliberate thinking hurts human performance.}
}

@inproceedings{geng2025large,
  title = {Are Large Language Models Reliable AI Scientists? Assessing Reverse-Engineering of Black-Box Systems},
  author = {Jiayi Geng* and Howard Chen* and Dilip Arumugam and Thomas L Griffiths},
  booktitle = {LM4Sci COLM Workshop 2025},
  year = {2025},
  month = {5},
  url = {https://arxiv.org/abs/2505.17968},
  code = {https://github.com/JiayiGeng/reverse-engineering},
  preview = {llm_scientists.png},
  selected = {true},
  description = {Evaluating the reliability of LLMs as AI scientists through reverse-engineering assessments of black-box systems.}
}

@misc{ku2025using,
  title = {Using the Tools of Cognitive Science to Understand Large Language Models at Different Levels of Analysis},
  author = {Alexander Ku and Declan Campbell and Xuechunzi Bai and Jiayi Geng and Ryan Liu and Raja Marjieh and R. Thomas McCoy and Andrew Nam and Ilia Sucholutsky and Veniamin Veselovsky and Liyi Zhang and Jian-Qiao Zhu and Thomas L Griffiths},
  journal = {Preprint},
  year = {2025},
  month = {3},
  url = {https://arxiv.org/abs/2503.13401},
  preview = {cognitive.png},
  selected = {true},
  description = {Applying cognitive science tools to understand LLMs at multiple levels of analysis.}
}

@inproceedings{liu2025rational,
  title = {Large Language Models Assume People are More Rational than We Really Are},
  author = {Ryan Liu* and Jiayi Geng* and Joshua C Peterson and Ilia Sucholutsky and Thomas L Griffiths},
  booktitle = {ICLR 2025},
  year = {2025},
  month = {1},
  url = {https://arxiv.org/abs/2406.17055},
  code = {https://github.com/theryanl/LLM-rationality},
  preview = {llm_rationality.png},
  selected = {true},
  description = {Showing that LLMs overestimate human rationality in their predictions of human behavior.}
}

@article{chen2024continual,
  title = {Continual Memorization of Factoids in Large Language Models},
  author = {Howard Chen* and Jiayi Geng* and Adithya Bhaskar and Dan Friedman and Danqi Chen},
  journal = {TMLR 2026},
  year = {2024},
  month = {11},
  url = {https://arxiv.org/abs/2411.07175},
  code = {https://github.com/princeton-nlp/continual-factoid-memorization},
  preview = {cm.png},
  selected = {true},
  description = {Investigating how large language models continually memorize factual knowledge over training.}
}

@inproceedings{qiu2024treebon,
  title = {TreeBoN: Enhancing Inference-Time Alignment with Speculative Tree-Search and Best-of-N Sampling},
  author = {Jiahao Qiu and Yifu Lu and Yifan Zeng and Jiacheng Guo and Jiayi Geng and Huazheng Wang and Kaixuan Huang and Yue Wu and Mengdi Wang},
  booktitle = {EMNLP Findings 2025},
  year = {2024},
  month = {10},
  url = {https://arxiv.org/abs/2410.16033},
  preview = {treebon.png},
  selected = {true},
  description = {A method combining speculative tree-search with best-of-N sampling for better inference-time alignment.}
}

@misc{zhang2024dr,
  title = {Dr. GPT in Campus Counseling: Understanding Higher Education Students' Opinions on LLM-assisted Mental Health Services},
  author = {Owen Xingjian Zhang and Shuyao Zhou and Jiayi Geng and Yuhan Liu and Sunny Xun Liu},
  journal = {Preprint},
  year = {2024},
  month = {9},
  url = {https://arxiv.org/abs/2409.17572},
  preview = {dr_gpt.png},
  selected = {false},
  description = {Understanding student opinions on LLM-assisted mental health services in campus counseling.}
}

@inproceedings{chevalier2024language,
  title = {Language Models as Science Tutors},
  author = {Alexis Chevalier and Jiayi Geng and Alexander Wettig and Howard Chen and Sebastian Mizera and Toni Annala and Max Jameson Aragon and Arturo Rodriguez Fanlo and Simon Frieder and Simon Machado and Akshara Prabhakar and Ellie Thieu and Jiachen T Wang and Zirui Wang and Xindi Wu and Mengzhou Xia and Wenhan Xia and Jiatong Yu and Jun-Jie Zhu and Zhiyong Jason Ren and Sanjeev Arora and Danqi Chen},
  booktitle = {ICML 2024},
  year = {2024},
  month = {7},
  url = {https://arxiv.org/abs/2402.11111},
  code = {https://github.com/princeton-nlp/LM-Science-Tutor},
  preview = {science_tutor.png},
  selected = {true},
  description = {Exploring the effectiveness of language models as science tutors for educational applications.}
}

@misc{zhang2023corgi,
  title = {Corgi-PM: A Chinese Corpus for Gender Bias Probing and Mitigation},
  author = {Ge Zhang and Yizhi Li and Yaoyao Wu and Linyuan Zhang and Chenghua Lin and Jiayi Geng and Shi Wang and Jie Fu},
  journal = {Preprint},
  year = {2023},
  month = {1},
  url = {https://arxiv.org/abs/2301.00395},
  code = {https://github.com/yizhilll/CORGI-PM},
  selected = {false},
  preview = {corgi.png},
  description = {A Chinese corpus designed for probing and mitigating gender bias in language models.}
}
